"""
51.ca ä¸»çˆ¬èŸ² - çˆ¬å–æ‰€æœ‰è³‡æ–™
ä½¿ç”¨ subprocess åˆ†åˆ¥é‹è¡Œæ¯å€‹çˆ¬èŸ²ï¼Œé¿å… asyncio loop è¡çª
"""
import sys
import time
import subprocess
import argparse
from datetime import datetime

from models import init_database, get_connection


def get_stats():
    """ç²å–ç•¶å‰è³‡æ–™åº«çµ±è¨ˆ"""
    conn = get_connection()
    c = conn.cursor()
    stats = {}
    tables = ['news_articles', 'house_listings', 'job_listings', 
              'service_merchants', 'service_posts', 'market_posts', 'auto_listings']
    for table in tables:
        try:
            c.execute(f'SELECT COUNT(*) FROM {table}')
            stats[table] = c.fetchone()[0]
        except:
            stats[table] = 0
    conn.close()
    return stats


def print_stats(stats, title="è³‡æ–™åº«çµ±è¨ˆ"):
    """æ‰“å°çµ±è¨ˆè³‡è¨Š"""
    print(f"\n{'='*50}")
    print(f"  {title}")
    print(f"{'='*50}")
    labels = {
        'news_articles': 'ğŸ“° æ–°è',
        'house_listings': 'ğŸ  æˆ¿æº',
        'job_listings': 'ğŸ’¼ å·¥ä½œ',
        'service_merchants': 'ğŸª å•†å®¶',
        'service_posts': 'ğŸ”§ æœå‹™å¸–',
        'market_posts': 'ğŸ›’ é›†å¸‚',
        'auto_listings': 'ğŸš— æ±½è»Š',
    }
    total = 0
    for table, count in stats.items():
        label = labels.get(table, table)
        print(f"  {label}: {count}")
        total += count
    print(f"{'='*50}")
    print(f"  ç¸½è¨ˆ: {total}")
    print(f"{'='*50}\n")
    return total


def run_scraper_subprocess(scraper_file: str, name: str, max_pages: int = 5):
    """ä½¿ç”¨ subprocess é‹è¡Œå–®å€‹çˆ¬èŸ²"""
    print(f"\n{'='*60}")
    print(f"  é–‹å§‹çˆ¬å–: {name}")
    print(f"{'='*60}")
    
    python_exe = sys.executable
    
    try:
        result = subprocess.run(
            [python_exe, scraper_file, '--max-pages', str(max_pages)],
            cwd='.',
            timeout=600  # 10 åˆ†é˜è¶…æ™‚
        )
        return result.returncode == 0
    except subprocess.TimeoutExpired:
        print(f"  âš ï¸ è¶…æ™‚")
        return False
    except Exception as e:
        print(f"  âŒ éŒ¯èª¤: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description='51.ca ä¸»çˆ¬èŸ²')
    parser.add_argument('--scrapers', nargs='+', 
                       choices=['news', 'house', 'jobs', 'service', 'market', 'auto', 'merchant', 'all'],
                       default=['all'],
                       help='è¦é‹è¡Œçš„çˆ¬èŸ² (é è¨­: all)')
    parser.add_argument('--max-pages', type=int, default=5,
                       help='æ¯å€‹çˆ¬èŸ²æœ€å¤šçˆ¬å–çš„é æ•¸ (é è¨­: 5)')
    args = parser.parse_args()
    
    print(f"\n{'#'*60}")
    print(f"  51.ca ä¸»çˆ¬èŸ²")
    print(f"  æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'#'*60}")
    
    # åˆå§‹åŒ–è³‡æ–™åº«
    init_database()
    
    # çˆ¬å–å‰çµ±è¨ˆ
    before_stats = get_stats()
    print_stats(before_stats, "çˆ¬å–å‰çµ±è¨ˆ")
    
    # ç¢ºå®šè¦é‹è¡Œçš„çˆ¬èŸ²
    scrapers_to_run = args.scrapers
    if 'all' in scrapers_to_run:
        scrapers_to_run = ['news', 'house', 'jobs', 'service', 'market', 'auto', 'merchant']
    
    start_time = time.time()
    results = {}
    
    # çˆ¬èŸ²å°æ‡‰çš„æ–‡ä»¶å’Œæ¨™ç±¤
    scraper_files = {
        'news': ('51_scraper_news.py', 'æ–°è'),
        'house': ('51_scraper_house.py', 'æˆ¿æº'),
        'jobs': ('51_scraper_jobs.py', 'å·¥ä½œ'),
        'service': ('51_scraper_service.py', 'æœå‹™'),
        'market': ('51_scraper_market.py', 'é›†å¸‚'),
        'auto': ('51_scraper_auto.py', 'æ±½è»Š'),
        'merchant': ('51_scraper_merchant.py', 'å•†å®¶'),
    }
    
    # ä½¿ç”¨ subprocess é‹è¡Œçˆ¬èŸ²
    for scraper_name in scrapers_to_run:
        if scraper_name in scraper_files:
            file, label = scraper_files[scraper_name]
            results[scraper_name] = run_scraper_subprocess(file, label, args.max_pages)
    
    # çˆ¬å–å¾Œçµ±è¨ˆ
    after_stats = get_stats()
    print_stats(after_stats, "çˆ¬å–å¾Œçµ±è¨ˆ")
    
    # è¨ˆç®—æ–°å¢æ•¸é‡
    print(f"\n{'='*50}")
    print(f"  æ–°å¢è³‡æ–™çµ±è¨ˆ")
    print(f"{'='*50}")
    total_new = 0
    labels = {
        'news_articles': 'ğŸ“° æ–°è',
        'house_listings': 'ğŸ  æˆ¿æº',
        'job_listings': 'ğŸ’¼ å·¥ä½œ',
        'service_merchants': 'ğŸª å•†å®¶',
        'service_posts': 'ğŸ”§ æœå‹™å¸–',
        'market_posts': 'ğŸ›’ é›†å¸‚',
        'auto_listings': 'ğŸš— æ±½è»Š',
    }
    for table in after_stats:
        new_count = after_stats[table] - before_stats.get(table, 0)
        if new_count > 0:
            label = labels.get(table, table)
            print(f"  {label}: +{new_count}")
            total_new += new_count
    print(f"{'='*50}")
    print(f"  ç¸½è¨ˆæ–°å¢: +{total_new}")
    print(f"{'='*50}")
    
    # åŸ·è¡Œæ™‚é–“
    elapsed = time.time() - start_time
    print(f"\nâ±ï¸ ç¸½åŸ·è¡Œæ™‚é–“: {elapsed:.1f} ç§’")
    
    # çµæœæ‘˜è¦
    print(f"\n{'='*50}")
    print(f"  åŸ·è¡Œçµæœ")
    print(f"{'='*50}")
    for name, success in results.items():
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
        print(f"  {name}: {status}")
    print(f"{'='*50}\n")


if __name__ == '__main__':
    main()
