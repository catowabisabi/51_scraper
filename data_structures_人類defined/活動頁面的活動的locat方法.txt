ğŸ” ä½ è¦æŠ½å˜…è³‡æ–™

æ¯å€‹æ´»å‹• liï¼š

ID â†’ data-id

æ¨™é¡Œ â†’ <h3><a>â€¦</a></h3>

é€£çµ â†’ <a href>

åœ–ç‰‡ â†’ <img src>

æ™‚é–“ â†’ <span class="time">

åœ°é» â†’ <span class="location">

é¡å‹ â†’ event / promotion

âœ… CSS Selectorï¼ˆå»ºè­°ç”¨ï¼‰

æ´»å‹• item

li.wg51__feeds-item.event


æ¨å»£ï¼ˆå»£å‘Šï¼‰

li.wg51__feeds-item.stream-mixed-large

ğŸ‘‰ æŠ½å­—æ®µ selector

ID

li.wg51__feeds-item.event a[data-id]


æ¨™é¡Œæ–‡å­—

li.wg51__feeds-item.event h3 a


æ´»å‹•é€£çµ

li.wg51__feeds-item.event h3 a


å°é¢åœ–

li.wg51__feeds-item.event img.cover-img


æ™‚é–“

li.wg51__feeds-item.event span.time


åœ°é»

li.wg51__feeds-item.event span.location

ğŸ Python ç›´æ¥çˆ¬ï¼ˆBeautifulSoupï¼‰

ï¼ˆä½ è©±è¦ code æˆ‘å°±ä¿¾ï¼Œå°‘è§£é‡‹ï¼‰

from bs4 import BeautifulSoup

soup = BeautifulSoup(html, "html.parser")

events = []

for li in soup.select("li.wg51__feeds-item.event"):
    a = li.select_one("h3 a")

    events.append({
        "id": a["data-id"],
        "title": a.get_text(strip=True),
        "url": a["href"],
        "image_url": li.select_one("img.cover-img")["src"],
        "time": li.select_one("span.time").get_text(strip=True),
        "location": li.select_one("span.location").get_text(strip=True),
        "type": "event"
    })

ğŸ§­ ä½ ä»²å¯ä»¥ç”¨ XPathï¼ˆå¦‚æœç”¨ scrapy / lxmlï¼‰
//li[contains(@class,"wg51__feeds-item") and contains(@class,"event")]


æ¨™é¡Œ

.//h3/a/text()


æ™‚é–“

.//span[@class="time"]/text()


åœ°é»

.//span[@class="location"]/text()

âš ï¸ å°å¿ƒä½

å…¥é¢å¤¾ä½ swiper æ¨å»£å¡ï¼Œè¦ filter

æœ‰å•² content ç©ºå˜…ï¼ˆ<div class="content">ï¼‰

lazyload åœ–å¯èƒ½ç”¨ data-srcï¼ˆç•™æ„ï¼‰

URL æœ‰ tracking parameterï¼Œè¦å””è¦æ¸…ç†ä½ è‡ªå·±æ±ºå®š